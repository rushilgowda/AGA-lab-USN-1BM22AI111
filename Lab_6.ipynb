{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rushilgowda/AGA-lab-USN-1BM22AI111/blob/main/Lab_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fcs872klZcw",
        "outputId": "3cca245e-3552-4f7e-94eb-9e9f23130927"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 45.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pretraining RBM 1...\n",
            "Pretraining RBM 2...\n",
            "Fine-tuning DBN...\n",
            "Epoch 1, Loss: 1.8508\n",
            "Epoch 2, Loss: 1.6549\n",
            "Epoch 3, Loss: 1.5462\n",
            "Epoch 4, Loss: 1.4538\n",
            "Epoch 5, Loss: 1.3676\n",
            "\n",
            "✅ DBN Accuracy on CIFAR-10: 45.27%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class RBM(nn.Module):\n",
        "    def __init__(self, n_visible, n_hidden, k=1):\n",
        "        super(RBM, self).__init__()\n",
        "        self.W = nn.Parameter(torch.randn(n_hidden, n_visible) * 0.01)\n",
        "        self.h_bias = nn.Parameter(torch.zeros(n_hidden))\n",
        "        self.v_bias = nn.Parameter(torch.zeros(n_visible))\n",
        "        self.k = k\n",
        "\n",
        "    def sample_h(self, v):\n",
        "        h_prob = torch.sigmoid(F.linear(v, self.W, self.h_bias))\n",
        "        return h_prob, torch.bernoulli(h_prob)\n",
        "\n",
        "    def sample_v(self, h):\n",
        "        v_prob = torch.sigmoid(F.linear(h, self.W.t(), self.v_bias))\n",
        "        return v_prob, torch.bernoulli(v_prob)\n",
        "\n",
        "    def contrastive_divergence(self, v, lr=0.01):\n",
        "        v0 = v\n",
        "        h0_prob, h0 = self.sample_h(v0)\n",
        "        for _ in range(self.k):\n",
        "            v1_prob, v1 = self.sample_v(h0)\n",
        "            h1_prob, h1 = self.sample_h(v1_prob)\n",
        "        self.W.data += lr * (torch.matmul(h0.t(), v0) - torch.matmul(h1_prob.t(), v1_prob)) / v0.size(0)\n",
        "        self.v_bias.data += lr * torch.mean(v0 - v1_prob, dim=0)\n",
        "        self.h_bias.data += lr * torch.mean(h0 - h1_prob, dim=0)\n",
        "\n",
        "\n",
        "class DBN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_sizes, output_size):\n",
        "        super(DBN, self).__init__()\n",
        "        self.rbm1 = RBM(input_size, hidden_sizes[0])\n",
        "        self.rbm2 = RBM(hidden_sizes[0], hidden_sizes[1])\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_sizes[0]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_sizes[1], output_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,)),\n",
        "    lambda x: x.view(-1)\n",
        "])\n",
        "\n",
        "train_data = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_data = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=1000)\n",
        "\n",
        "\n",
        "input_size = 32 * 32\n",
        "hidden_sizes = [512, 256]\n",
        "output_size = 10\n",
        "\n",
        "rbm1 = RBM(input_size, hidden_sizes[0])\n",
        "rbm2 = RBM(hidden_sizes[0], hidden_sizes[1])\n",
        "\n",
        "print(\"Pretraining RBM 1...\")\n",
        "for epoch in range(5):\n",
        "    for x, _ in train_loader:\n",
        "        rbm1.contrastive_divergence(x)\n",
        "\n",
        "print(\"Pretraining RBM 2...\")\n",
        "with torch.no_grad():\n",
        "    h1_all = []\n",
        "    for x, _ in train_loader:\n",
        "        h1, _ = rbm1.sample_h(x)\n",
        "        h1_all.append(h1)\n",
        "    h1_all = torch.cat(h1_all)\n",
        "\n",
        "\n",
        "labels_tensor = torch.tensor(train_data.targets)\n",
        "h1_loader = DataLoader(TensorDataset(h1_all, labels_tensor), batch_size=64, shuffle=True)\n",
        "\n",
        "for epoch in range(5):\n",
        "    for h1, _ in h1_loader:\n",
        "        rbm2.contrastive_divergence(h1)\n",
        "\n",
        "\n",
        "dbn = DBN(input_size, hidden_sizes, output_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(dbn.parameters(), lr=0.001)\n",
        "\n",
        "print(\"Fine-tuning DBN...\")\n",
        "for epoch in range(5):\n",
        "    dbn.train()\n",
        "    total_loss = 0\n",
        "    for x, y in train_loader:\n",
        "        output = dbn(x)\n",
        "        loss = criterion(output, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader):.4f}\")\n",
        "\n",
        "\n",
        "dbn.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for x, y in test_loader:\n",
        "        pred = dbn(x).argmax(dim=1)\n",
        "        correct += (pred == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "accuracy = 100. * correct / total\n",
        "print(f\"\\n✅ DBN Accuracy on CIFAR-10: {accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "REQ3ebaFlaCu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}